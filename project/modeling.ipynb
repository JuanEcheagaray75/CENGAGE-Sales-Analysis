{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación y Evaluación de Modelos \n",
    "\n",
    "- Análisis de Ciencias de Datos\n",
    "- TC2004B.100\n",
    "- Profesores:\n",
    "  - Daniel Otero Fadul\n",
    "  - Rubí Isela Gutiérrez López\n",
    "- Equipo 4:\n",
    "\n",
    "| Nombre | Matrícula |\n",
    "| ---- | ---- |\n",
    "| Juan Pablo Echeagaray González | A00830646 |\n",
    "| Emily Rebeca Méndez Cruz | A00830768 |\n",
    "| Eugenio Santisteban Zolezzi | A01720932 |\n",
    "| Taurino López González | A01284076 |\n",
    "| Ricardo de Jesús Balam Ek | A00831262 |\n",
    "| Grace Aviance Silva Aróstegui | A01285158 |\n",
    "\n",
    "Fecha: 17 de marzo del 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propósito\n",
    "\n",
    "Para esta actividad realizarás la creación y evaluación de modelos utilizando los datos que procesaste y analizaste en la actividad anterior.\n",
    "\n",
    "## Instrucciones\n",
    "\n",
    "Implementarás dos o más modelos de \"machine learning\" que consideres relevantes para tu proyecto y los evaluarás utilizando algunas de las métricas vistas en clase. A parte del código que deberás escribir, también se requiere que junto con este, escribas un reporte en el cual describas los pasos que vas realizando en el proceso y finalizar con unas conclusiones en las que hables de tus hallazgos.\n",
    "\n",
    "Por cierto, esta entrega es revisada por UNICHECK. Dicho esto, todo su trabajo debe ser de su autoría. Si incluyen código o texto que no sea escrito por ustedes debe citarse la fuente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paquetes utilizados:\n",
      "- python: 3.9.7 (tags/v3.9.7:1016ef3, Aug 30 2021, 20:19:38) [MSC v.1929 64 bit (AMD64)]\n",
      "- numpy: 1.22.2\n",
      "- pandas: 1.1.4\n",
      "- matplotlib: 3.4.1\n",
      "- seaborn: 0.11.1\n",
      "- sklearn: 1.0.2\n"
     ]
    }
   ],
   "source": [
    "# Dependencias básicas\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Tratamiento de variables, selección de variables, entrenamiento de modelos predictivos\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Versiones de librerías utilizadas\n",
    "print(f'''Paquetes utilizados:\n",
    "- python: {sys.version}\n",
    "- numpy: {np.__version__}\n",
    "- pandas: {pd.__version__}\n",
    "- matplotlib: {mpl.__version__}\n",
    "- seaborn: {sns.__version__}\n",
    "- sklearn: {sklearn.__version__}''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo que tomaremos como base de datos para el proceso de entrenamiento de modelos será la base de datos que hemos limpiado en la etapa anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Consultant</th>\n",
       "      <th>Opportunity ID</th>\n",
       "      <th>Account</th>\n",
       "      <th>ISBN 13</th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Probability</th>\n",
       "      <th>% de Avance</th>\n",
       "      <th>Term</th>\n",
       "      <th>...</th>\n",
       "      <th>Units</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Technology</th>\n",
       "      <th>Course Name</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Course ID</th>\n",
       "      <th>Customer</th>\n",
       "      <th>Client</th>\n",
       "      <th>Log revenue</th>\n",
       "      <th>Coded Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>14</td>\n",
       "      <td>5255970</td>\n",
       "      <td>colegio de bachilleres de chihuahua</td>\n",
       "      <td>9.786075e+12</td>\n",
       "      <td>martinez</td>\n",
       "      <td>literatura ii</td>\n",
       "      <td>No_Aceptada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>...</td>\n",
       "      <td>8929</td>\n",
       "      <td>1308277.08</td>\n",
       "      <td>Copia física</td>\n",
       "      <td>literatura   cobach</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1847125</td>\n",
       "      <td>Potential Customer</td>\n",
       "      <td>3705</td>\n",
       "      <td>14.084222</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>10</td>\n",
       "      <td>5172372</td>\n",
       "      <td>u-erre universidad regiomontana</td>\n",
       "      <td>9.781338e+12</td>\n",
       "      <td>serway/vuille</td>\n",
       "      <td>intl iac wa fundamentos de fis ica</td>\n",
       "      <td>Closed Sale</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>1161600.00</td>\n",
       "      <td>WebAssign</td>\n",
       "      <td>fisica 1 prepa u-erre</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1905363</td>\n",
       "      <td>Potential Customer</td>\n",
       "      <td>3681</td>\n",
       "      <td>13.965309</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>6</td>\n",
       "      <td>4496314</td>\n",
       "      <td>itesm campus monterrey</td>\n",
       "      <td>9.786075e+12</td>\n",
       "      <td>cengage</td>\n",
       "      <td>biblioteca digital magellan</td>\n",
       "      <td>No_Aceptada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>779999.95</td>\n",
       "      <td>Copia física</td>\n",
       "      <td>biblioteca digital</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1873177</td>\n",
       "      <td>Potential Customer</td>\n",
       "      <td>5929</td>\n",
       "      <td>13.567049</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>5745690</td>\n",
       "      <td>unitec campus cuitlahuac</td>\n",
       "      <td>9.786076e+12</td>\n",
       "      <td>galindo</td>\n",
       "      <td>modelos de organización</td>\n",
       "      <td>Evaluation Visit</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2000</td>\n",
       "      <td>600000.00</td>\n",
       "      <td>Copia física</td>\n",
       "      <td>estructuras organizacionales y gestión del con...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1934416</td>\n",
       "      <td>Potential Customer</td>\n",
       "      <td>2538</td>\n",
       "      <td>13.304685</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>5745686</td>\n",
       "      <td>unitec campus cuitlahuac</td>\n",
       "      <td>9.786076e+12</td>\n",
       "      <td>galindo</td>\n",
       "      <td>modelos de organización</td>\n",
       "      <td>Evaluation Visit</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2000</td>\n",
       "      <td>600000.00</td>\n",
       "      <td>Copia física</td>\n",
       "      <td>estructuras organizacionales y gestión del con...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1934416</td>\n",
       "      <td>Potential Customer</td>\n",
       "      <td>2538</td>\n",
       "      <td>13.304685</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country  Consultant  Opportunity ID                              Account  \\\n",
       "0  Mexico          14         5255970  colegio de bachilleres de chihuahua   \n",
       "1  Mexico          10         5172372      u-erre universidad regiomontana   \n",
       "2  Mexico           6         4496314               itesm campus monterrey   \n",
       "3  Mexico           0         5745690             unitec campus cuitlahuac   \n",
       "4  Mexico           0         5745686             unitec campus cuitlahuac   \n",
       "\n",
       "        ISBN 13         Author                               Title  \\\n",
       "0  9.786075e+12       martinez                       literatura ii   \n",
       "1  9.781338e+12  serway/vuille  intl iac wa fundamentos de fis ica   \n",
       "2  9.786075e+12        cengage         biblioteca digital magellan   \n",
       "3  9.786076e+12        galindo             modelos de organización   \n",
       "4  9.786076e+12        galindo             modelos de organización   \n",
       "\n",
       "        Probability  % de Avance        Term  ...  Units     Revenue  \\\n",
       "0       No_Aceptada          NaN  2021-08-01  ...   8929  1308277.08   \n",
       "1       Closed Sale         1.00  2021-01-01  ...     22  1161600.00   \n",
       "2       No_Aceptada          NaN  2020-09-01  ...      2   779999.95   \n",
       "3  Evaluation Visit         0.75  2022-05-01  ...   2000   600000.00   \n",
       "4  Evaluation Visit         0.75  2022-01-01  ...   2000   600000.00   \n",
       "\n",
       "     Technology                                        Course Name Edition  \\\n",
       "0  Copia física                                literatura   cobach     1.0   \n",
       "1     WebAssign                              fisica 1 prepa u-erre    11.0   \n",
       "2  Copia física                                 biblioteca digital     1.0   \n",
       "3  Copia física  estructuras organizacionales y gestión del con...     1.0   \n",
       "4  Copia física  estructuras organizacionales y gestión del con...     1.0   \n",
       "\n",
       "   Course ID            Customer Client  Log revenue  Coded Probability  \n",
       "0    1847125  Potential Customer   3705    14.084222               0.00  \n",
       "1    1905363  Potential Customer   3681    13.965309               1.00  \n",
       "2    1873177  Potential Customer   5929    13.567049               0.00  \n",
       "3    1934416  Potential Customer   2538    13.304685               0.75  \n",
       "4    1934416  Potential Customer   2538    13.304685               0.75  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoding para variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_types = df['Technology'].unique()\n",
    "tech_dum = pd.get_dummies(df, columns=['Technology'], prefix=['Tech_'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = tech_dum['Country'].unique()\n",
    "country_dum = pd.get_dummies(tech_dum, columns=['Country'], prefix=['Country_'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diferencia de columnas\n",
      "# de columnas nuevas: 20\n",
      "Columnas añadidas: Index(['Country__Colombia', 'Country__Costa Rica',\n",
      "       'Country__Dominican Republic', 'Country__Ecuador',\n",
      "       'Country__El Salvador', 'Country__Guatemala', 'Country__Honduras',\n",
      "       'Country__Mexico', 'Country__Nicaragua', 'Country__Panama',\n",
      "       'Tech__CengageNOW', 'Tech__CengageNOWv2', 'Tech__Copia física',\n",
      "       'Tech__MindTap', 'Tech__MindTap - MT4', 'Tech__MindTap with LivePlan',\n",
      "       'Tech__MyELT', 'Tech__OWLv2', 'Tech__Other Digital', 'Tech__WebAssign'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get added columns from df and country_dum\n",
    "df_cols = df.columns\n",
    "country_dum_cols = country_dum.columns\n",
    "added_cols = country_dum_cols.difference(df_cols)\n",
    "print(f'''Diferencia de columnas\n",
    "# de columnas nuevas: {len(added_cols)}\n",
    "Columnas añadidas: {added_cols}''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al final del proceso acabamos con 20 variables nuevas, hemos de destacar desde esta etapa que el número de variables es grande. El usar todas podría hacer que los modelos que entrenemos sean en exceso complejos, quitándoles la habilidad de generalizar a nuevos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cols = ['Consultant', 'Coded Probability', 'Edition', 'Seats', 'Units', 'Tech__CengageNOW',\n",
    "       'Tech__CengageNOWv2', 'Tech__Copia física', 'Tech__MindTap',\n",
    "       'Tech__MindTap - MT4', 'Tech__MindTap with LivePlan', 'Tech__MyELT',\n",
    "       'Tech__OWLv2', 'Tech__Other Digital', 'Tech__WebAssign', 'Country__Colombia', 'Country__Costa Rica',\n",
    "       'Country__Dominican Republic', 'Country__Ecuador',\n",
    "       'Country__El Salvador', 'Country__Guatemala', 'Country__Honduras',\n",
    "       'Country__Mexico', 'Country__Nicaragua', 'Country__Panama']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de conjuntos de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un primer paso que debemos de tomar es la estandarización de datos. Los modelos regresores trabajan mejor cuando todas las variables tienen rangos similares, esto ayuda a reducir la dominancia que podría tomar una variable que tenga un rango en órdenes de magnitud de miles contra otra que trabaja con valores de 0 a 1 por ejemplo.\n",
    "\n",
    "Para realizar esta tarea hacemos uso del estandarizador de datos de `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(country_dum[test_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Log Revenue'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Log Revenue'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13324/989617589.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcountry_dum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Log Revenue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcountry_dum\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaled_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2906\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2907\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Log Revenue'"
     ]
    }
   ],
   "source": [
    "y = country_dum['Log Revenue']\n",
    "X = country_dum[test_cols]\n",
    "X_2 = scaled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos normales\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos estandarizados\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_2, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nuestra investigación, hemos decidido utilizar modelos de regresión para predecir el `Revenue` generado dada una operación. Como posibles candidatos tenemos varios modelos de regresión lineal, entre ellos están la simple, ridge y lasso; y al árbol de decisión en su modalidad regresora. Como métricas de comparación se usarán el coeficiente de determinación y el error cuadrático medio.\n",
    "\n",
    "Como punto de referencia, se desea que el coeficiente de determinación (`r2`) sea lo más cercano posible a 1, y el error cuadrático medio debe de ser lo más cercano a 0 que se pueda. Se incluirá también el puntaje en el conjunto de prueba como un dato extra. Su valor siempre será superior al coeficiente de determinación, pero de cualquier manera sirve para comparar de antemano como se comportan los modelos con datos que ya vieron.\n",
    "\n",
    "Los modelos y métricas a usar son aquellos implementados en la librería de `scikit-learn`, estándar en la comunidad de ciencias de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "results_df = pd.DataFrame(columns=['Model', 'Train Score', 'MSE', 'R2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(model_name: str,fun_model: callable, X_train, X_test, y_train, y_test):\n",
    "    # Función auxiliar que genera un diccionario con las principales métricas de un modelo\n",
    "    y_pred = fun_model.predict(X_test)\n",
    "    return {'Model': model_name, 'Train Score': fun_model.score(X_train, y_train), \n",
    "        'MSE': mean_squared_error(y_test, y_pred), 'R2': r2_score(y_test, y_pred)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de decisión regresores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree = DecisionTreeRegressor(max_depth=9, random_state=0)\n",
    "my_tree.fit(X_train, y_train)\n",
    "\n",
    "results_df = results_df.append(report('Árbol Regresor', my_tree, X_train, X_test, y_train, y_test), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_2 = DecisionTreeRegressor(max_depth=9, random_state=0)\n",
    "tree_2.fit(X_train2, y_train2)\n",
    "\n",
    "results_df = results_df.append(report('Árbol Regresor Estandarizado', tree_2, X_train2, X_test2, y_train2, y_test2), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg = LinearRegression()\n",
    "lrg.fit(X_train, y_train)\n",
    "\n",
    "results_df = results_df.append(report('Regresor Lineal', lrg, X_train, X_test, y_train, y_test), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.2)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "results_df = results_df.append(report('Ridge', ridge, X_train, X_test, y_train, y_test), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge2 = Ridge(alpha=0.2)\n",
    "ridge2.fit(X_train2, y_train2)\n",
    "\n",
    "results_df = results_df.append(report('Ridge Estandarizado', ridge2, X_train2, X_test2, y_train2, y_test2), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "results_df = results_df.append(report('Lasso', lasso, X_train, X_test, y_train, y_test), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso2 = Lasso(alpha=0.1)\n",
    "lasso2.fit(X_train2, y_train2)\n",
    "\n",
    "results_df = results_df.append(report('Lasso Estandarizado', lasso2, X_train2, X_test2, y_train2, y_test2), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "fig.figuresize = (20, 8)\n",
    "sns.set()\n",
    "sns.barplot(x='Model', y='Train Score', data=results_df, ax=axes[0])\n",
    "sns.barplot(x='Model', y='MSE', data=results_df, ax=axes[1])\n",
    "sns.barplot(x='Model', y='R2', data=results_df, ax=axes[2])\n",
    "\n",
    "titles = ['Train Score', 'MSE', 'R2']\n",
    "\n",
    "for ax, title in zip(axes, titles):\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "    ax.set_title(title)\n",
    "\n",
    "fig.suptitle('Desempeño de los modelos');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de estas pruebas iniciales vemos que los modelos lineales no son capaces de capturar las relaciones que hay entre las variables numéricas de la base de datos y el `Revenue` logrado; el único regresor que tuvo un desempeño prometedor fue el árbol de decisión. De ahora en adelante nos enfocaremos en optimizar este método, encontrando los parámetros que maximicen su poder predictivo.\n",
    "\n",
    "> Como nota, el modelo de regresión lineal con datos estandarizados no fue incluido en la visualización anterior. El error cuadrado medio de este modelo era tan grande que no dejaba visualizar los resultados de los demás modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducción de dimensionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La visualización anterior compara las medidas de desempeño para nuestros modelos iniciales usando el `dataframe` que contiene las 20 variables nuevas. Este conjunto de datos fue a su vez usado estandarizado y sin estandarizar. Ahora que ya sabemos que de entre todos, los árboles de decisión regresores que usan datos estandarizados son los que tienen un mejor desempeño, podemos enfocarnos en verificar si es que podemos reducir el número de variables que los modelos utilicen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = tree_2.feature_importances_\n",
    "names = test_cols\n",
    "n = 10\n",
    "importances_df = pd.DataFrame({'Feature': names, 'Importance': importances}).sort_values('Importance', ascending=False)\n",
    "top_n_features = importances_df.head(n)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_n_features, palette='deep')\n",
    "plt.title('Importancia de las variables', fontsize=16);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la mayoría de las variables no tienen mucha importancia para el modelo en general. Podemos descartar la mayoría y solamente quedarnos con unas cuantas. Como equipo proponemos quedarnos con las mejores 5:\n",
    "\n",
    "1. Units\n",
    "2. Seats\n",
    "3. Country__Mexico\n",
    "4. Consultant\n",
    "5. Edition\n",
    "\n",
    "Los valores de importancia representados en la gráfica anterior son una representación directa del valor predictivo que tienen para el árbol regresor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este punto de nuestro trabajo de investigación ya hemos comprobado que el `Revenue` no puede ser modelado como una relación lineal de las variables que se encuentran en las bases de datos. De nuestros resultados experimentales hemos visto que un árbol de decisión regresor es quien suele tener un desempeño mayor.\n",
    "\n",
    "Ahora que nos hemos centrado en un tipo de modelo, podemos comenzar a hacer una validación cruzada en conjunto de un `GridSearch`. Usando estas 2 herramientas podremos encontrar cómo se comporta en promedio este modelo predictivo, además de que sabremos cuáles son los hiperparámetros que mejor se ajustan al `Revenue`. Como número de $\\text{k-folds}$ usaremos el estándar general de 5, aumentar este valor nos permitiría obtener una métrica más precisa del comportamiento promedio del modelo, pero requeriría de más tiempo hacer la operación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = country_dum\n",
    "\n",
    "X = testing_df[['Units', 'Seats', 'Country__Mexico', 'Consultant', 'Edition']]\n",
    "y = testing_df['Log Revenue']\n",
    "\n",
    "# Estandarizar los datos X\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nota, no estamos usando la columna del `Revenue` directamente, sino que hemos optado por usar el logaritmo de este. La variable de `Revenue` tiene una dispersión muy alta que un modelo regresor no podrá capturar tan fácilmente, al transformar esta columna con el logaritmo natural hemos reducido el grado de dispersión, facilitando así la predicción de este valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_data, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': [i for i in range(1, 20)], 'splitter': ['best', 'random'], 'random_state': [0]}\n",
    "clf = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5, scoring='r2', )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''Mejor modelo:.\n",
    "Mejores parámetros: {clf.best_params_}\n",
    "Mejor puntaje: {clf.best_score_ * 100:.2f}%\n",
    "MSE: {mean_squared_error(y_test, clf.predict(X_test))}\n",
    "Promedio de scores: {np.mean(clf.cv_results_['mean_test_score']) * 100:.2f}%''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = clf.best_estimator_\n",
    "best_tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de realizar la validación cruzada y el `GridSearch`, encontramos que en promedio un árbol de decisión regresor tendrá un puntaje de 58.16%, y que la mejor variante de árbol de decisión regresor es aquella que tiene una máxima profundidad de 19, su coeficiente de determinación es de 75.82%\n",
    "\n",
    "Con este modelo CENGAGE podría atribuir el 75.82% de sus ganancias generadas a las predicciones del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Revenue` predicho por el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_pred = np.exp(best_tree.predict(scaler.fit_transform(X)))\n",
    "# Add the predicted revenue to the dataframe\n",
    "country_dum['Predicted Revenue'] = rev_pred\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "plt.figure(figsize=(17, 6))\n",
    "agg_revenue_term = country_dum.groupby('Term').sum()['Revenue']\n",
    "predicted_agg_revenue_term = country_dum.groupby('Term').sum()['Predicted Revenue']\n",
    "ax = sns.lineplot(x=agg_revenue_term.index, y=agg_revenue_term, label='Revenue')\n",
    "ax2 = sns.lineplot(x=predicted_agg_revenue_term.index, y=predicted_agg_revenue_term, label='Predicted Revenue')\n",
    "plt.xticks(agg_revenue_term.index, rotation=45)\n",
    "\n",
    "# Encontrar los máximos locales\n",
    "peaks, _ = find_peaks(agg_revenue_term, distance=5)\n",
    "# Plot the peaks\n",
    "plt.plot(agg_revenue_term.index[peaks],\n",
    "         agg_revenue_term[peaks], \"*\", markersize=15, color='gold')\n",
    "\n",
    "ax.set_title('Comparación de los ingresos reales y los ingresos predichos');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respecto al entrenamiento de diferentes modelos predictivos podemos decir que la relación que existe entre las variables de la base de datos es de un carácter no lineal, por lo que en general, modelos que tengan este formato no se desempeñarán de manera óptima.\n",
    "\n",
    "Después de nuestro proceso de investigación hemos encontrado que un árbol de decisión regresor con profundidad máxima de 19 tiene la mejor capacidad de predecir el `Revenue` generado por una operación dada. El modelo que encontramos tiene un coeficiente de determinación $R_2$ de 0.7582, y $MSE$ (error cuadrático medio) de 0.403.\n",
    "\n",
    "Como recordatorio, tiene que hacerse una transformación de la predicción generada por el modelo, actualmente los datos que regresa la predicción son valores logarítmicos, las ganancias predichas deben de ser exponenciadas para obtener las ganancias reales."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a78c4be66ba3b4a897c6e596b18611fdff70693afae29e50365a94a133cff73c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
